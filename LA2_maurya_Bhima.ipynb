{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lab Assignment 2 - Sentiment Analysis\n",
        "\n",
        "Author Name : maurya sasanka Bhima\n",
        "\n",
        "ASU ID : 1234108592\n",
        "\n",
        "File Creation Date : 02/02/2025"
      ],
      "metadata": {
        "id": "riO9mVTfYfYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import Necessary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the restaurant review data\n",
        "file_path = '/content/restaurant_reviews_az.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "print(\"Sample Data from the Dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Showing basic dataset information\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Displaying column names\n",
        "print(\"\\nColumn Names:\", data.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_sIgVe4-crC",
        "outputId": "cbc5112e-9754-43b6-a8d8-b0dd7e6b20cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data from the Dataset:\n",
            "                review_id                 user_id             business_id  \\\n",
            "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
            "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
            "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
            "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
            "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
            "\n",
            "   stars  useful  funny  cool  \\\n",
            "0      3       1      1     0   \n",
            "1      5       1      1     1   \n",
            "2      5       1      0     0   \n",
            "3      5       0      0     0   \n",
            "4      4       1      0     0   \n",
            "\n",
            "                                                text                 date  \n",
            "0  OK, the hype about having Hatch chili in your ...  2020-01-27 22:59:06  \n",
            "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16  \n",
            "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44  \n",
            "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07  \n",
            "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57  \n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48147 entries, 0 to 48146\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   review_id    48147 non-null  object\n",
            " 1   user_id      48147 non-null  object\n",
            " 2   business_id  48147 non-null  object\n",
            " 3   stars        48147 non-null  int64 \n",
            " 4   useful       48147 non-null  int64 \n",
            " 5   funny        48147 non-null  int64 \n",
            " 6   cool         48147 non-null  int64 \n",
            " 7   text         48147 non-null  object\n",
            " 8   date         48147 non-null  object\n",
            "dtypes: int64(4), object(5)\n",
            "memory usage: 3.3+ MB\n",
            "None\n",
            "\n",
            "Column Names: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 3-star reviews\n",
        "filtered_data = data[data['stars'] != 3].copy()\n",
        "\n",
        "# Create the Sentiment column: 0 for 1-2 stars, 1 for 4-5 stars\n",
        "filtered_data['Sentiment'] = np.where(filtered_data['stars'] <= 2, 0, 1)\n",
        "\n",
        "# Display the updated dataset\n",
        "print(\"Sample Data After Filtering:\")\n",
        "print(filtered_data.head())\n",
        "\n",
        "# Show the value counts for Sentiment column to verify the distribution\n",
        "print(\"\\nSentiment Distribution:\")\n",
        "print(filtered_data['Sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cMI0ROA-0l_",
        "outputId": "f1c7e3d1-e290-4613-fa61-63bdd0d35a49"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data After Filtering:\n",
            "                review_id                 user_id             business_id  \\\n",
            "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
            "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
            "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
            "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
            "5  kx6O_lyLzUnA7Xip5wh2NA  YsINprB2G1DM8qG1hbrPUg  rViAhfKLKmwbhTKROM9m0w   \n",
            "\n",
            "   stars  useful  funny  cool  \\\n",
            "1      5       1      1     1   \n",
            "2      5       1      0     0   \n",
            "3      5       0      0     0   \n",
            "4      4       1      0     0   \n",
            "5      1       0      0     0   \n",
            "\n",
            "                                                text                 date  \\\n",
            "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16   \n",
            "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44   \n",
            "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07   \n",
            "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57   \n",
            "5  I stay at the Main Hotel at the Casino from Ju...  2020-07-14 16:43:23   \n",
            "\n",
            "   Sentiment  \n",
            "1          1  \n",
            "2          1  \n",
            "3          1  \n",
            "4          1  \n",
            "5          0  \n",
            "\n",
            "Sentiment Distribution:\n",
            "Sentiment\n",
            "1    31781\n",
            "0    12312\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the data and prepare training and test sets\n",
        "# Assume the review text is stored in a column named 'text'\n",
        "X = data['text']\n",
        "y = data['Sentiment']\n",
        "\n",
        "# Split the data into training (80%) and test (20%) sets, with a fixed random state for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set size:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTJ8j3UJu8PU",
        "outputId": "c21e2d80-c35b-407f-c839-9c09e5c34ab1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (35274,) (35274,)\n",
            "Test set size: (8819,) (8819,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Represent documents using CountVectorizer (frequency count representation)\n",
        "# Initialize CountVectorizer with a maximum of 1000 features\n",
        "count_vect = CountVectorizer(max_features=1000)\n",
        "\n",
        "# Fit CountVectorizer on the training data and transform both training and test data\n",
        "X_train_count = count_vect.fit_transform(X_train)\n",
        "X_test_count = count_vect.transform(X_test)\n",
        "\n",
        "# Display the shapes of the transformed datasets\n",
        "print(\"CountVectorizer - Training data shape:\", X_train_count.shape)\n",
        "print(\"CountVectorizer - Test data shape:\", X_test_count.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtDe4xFnvCmC",
        "outputId": "ddce03e5-d1b6-47f4-ec68-8582a08bf2cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer - Training data shape: (35274, 1000)\n",
            "CountVectorizer - Test data shape: (8819, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train a Naive Bayes classifier using CountVectorizer features and evaluate its performance\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "nb_classifier_count = MultinomialNB()\n",
        "\n",
        "# Train the classifier on the count vectorized training data\n",
        "nb_classifier_count.fit(X_train_count, y_train)\n",
        "\n",
        "# Predict sentiments for the test data\n",
        "y_pred_nb_count = nb_classifier_count.predict(X_test_count)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy_nb_count = accuracy_score(y_test, y_pred_nb_count)\n",
        "print(\"Naive Bayes (CountVectorizer) Accuracy:\", accuracy_nb_count)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLuprsd-GtS-",
        "outputId": "f3d7b1b0-9be8-43dc-e6d2-55f98fcd9ab0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes (CountVectorizer) Accuracy: 0.9209660959292437\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86      2554\n",
            "           1       0.94      0.95      0.94      6265\n",
            "\n",
            "    accuracy                           0.92      8819\n",
            "   macro avg       0.91      0.90      0.90      8819\n",
            "weighted avg       0.92      0.92      0.92      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train an SVM classifier using CountVectorizer features and evaluate its performance\n",
        "\n",
        "# Initialize a Linear SVM classifier with a fixed random state for reproducibility\n",
        "svm_classifier_count = LinearSVC(random_state=42)\n",
        "\n",
        "# Train the SVM classifier on the count vectorized training data\n",
        "svm_classifier_count.fit(X_train_count, y_train)\n",
        "\n",
        "# Predict sentiments for the test data using the SVM classifier\n",
        "y_pred_svm_count = svm_classifier_count.predict(X_test_count)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy_svm_count = accuracy_score(y_test, y_pred_svm_count)\n",
        "print(\"SVM (CountVectorizer) Accuracy:\", accuracy_svm_count)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2T5kwEHvKq-",
        "outputId": "70326dcf-ae86-4459-e340-0cca5346a716"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (CountVectorizer) Accuracy: 0.9477264996031296\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      2554\n",
            "           1       0.96      0.97      0.96      6265\n",
            "\n",
            "    accuracy                           0.95      8819\n",
            "   macro avg       0.94      0.93      0.94      8819\n",
            "weighted avg       0.95      0.95      0.95      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Represent documents using the TF-IDF vectorizer\n",
        "# Initialize TF-IDF Vectorizer with a maximum of 1000 features\n",
        "tfidf_vect = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "# Fit and transform the training data using TF-IDF and transform the test data\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vect.transform(X_test)\n",
        "\n",
        "# Print the shapes of the TF-IDF transformed datasets\n",
        "print(\"TF-IDF - Training data shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF - Test data shape:\", X_test_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35_gTIhLvP7M",
        "outputId": "03b32a12-aaff-4891-9208-fca00316450c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF - Training data shape: (35274, 1000)\n",
            "TF-IDF - Test data shape: (8819, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train a Naive Bayes classifier using TF-IDF features and evaluate its performance\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "nb_classifier_tfidf = MultinomialNB()\n",
        "\n",
        "# Train the classifier on the TF-IDF training data\n",
        "nb_classifier_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict sentiments for the test data using the TF-IDF features\n",
        "y_pred_nb_tfidf = nb_classifier_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy_nb_tfidf = accuracy_score(y_test, y_pred_nb_tfidf)\n",
        "print(\"Naive Bayes (TF-IDF) Accuracy:\", accuracy_nb_tfidf)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_tfidf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OGXc-OAvWLs",
        "outputId": "0f20cf53-1ca9-4e86-9a78-ced4c9e587a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes (TF-IDF) Accuracy: 0.9070189363873455\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.73      0.82      2554\n",
            "           1       0.90      0.98      0.94      6265\n",
            "\n",
            "    accuracy                           0.91      8819\n",
            "   macro avg       0.92      0.85      0.88      8819\n",
            "weighted avg       0.91      0.91      0.90      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train an SVM classifier using TF-IDF features and evaluate its performance\n",
        "\n",
        "# Initialize a Linear SVM classifier for TF-IDF features\n",
        "svm_classifier_tfidf = LinearSVC(random_state=42)\n",
        "\n",
        "# Train the SVM classifier on the TF-IDF training data\n",
        "svm_classifier_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict sentiments for the test data using the SVM classifier\n",
        "y_pred_svm_tfidf = svm_classifier_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy_svm_tfidf = accuracy_score(y_test, y_pred_svm_tfidf)\n",
        "print(\"SVM (TF-IDF) Accuracy:\", accuracy_svm_tfidf)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_tfidf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O0XiyQrvsDB",
        "outputId": "5184ad27-996e-4bab-ad47-3e7bfaa7ea23"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (TF-IDF) Accuracy: 0.9499943304229505\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.91      2554\n",
            "           1       0.96      0.97      0.96      6265\n",
            "\n",
            "    accuracy                           0.95      8819\n",
            "   macro avg       0.94      0.94      0.94      8819\n",
            "weighted avg       0.95      0.95      0.95      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Use the VADER sentiment analyzer to predict review sentiment and evaluate its performance\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define a function to classify sentiment based on VADER's compound score.\n",
        "# Here, we set sentiment 1 (positive) if compound score >= 0.05; otherwise, sentiment 0 (negative).\n",
        "def get_vader_sentiment(text):\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    return 1 if scores['compound'] >= 0.05 else 0\n",
        "\n",
        "# Apply the VADER sentiment function to each review in the test set\n",
        "y_pred_vader = X_test.apply(get_vader_sentiment)\n",
        "\n",
        "# Evaluate the VADER sentiment predictions\n",
        "accuracy_vader = accuracy_score(y_test, y_pred_vader)\n",
        "print(\"VADER Sentiment Analysis Accuracy:\", accuracy_vader)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_vader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iyEniYHwbwv",
        "outputId": "d972f446-896c-45d9-bd6f-c68a28a4497e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER Sentiment Analysis Accuracy: 0.8668783308765167\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.59      0.72      2554\n",
            "           1       0.85      0.98      0.91      6265\n",
            "\n",
            "    accuracy                           0.87      8819\n",
            "   macro avg       0.89      0.79      0.82      8819\n",
            "weighted avg       0.87      0.87      0.86      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observations\n",
        "Naive Bayes (CountVectorizer)\n",
        "Accuracy: 92.1%\n",
        "Precision/Recall Breakdown:\n",
        "Negative Reviews (Class 0): 87% Precision, 86% Recall\n",
        "Positive Reviews (Class 1): 94% Precision, 95% Recall\n",
        "Observation: Naive Bayes performs well, especially in predicting positive sentiments. However, it slightly struggles with misclassifying negative reviews.\n",
        "\n",
        "Support Vector Machine (SVM) with CountVectorizer\n",
        "Performance details not extracted, but SVM models usually outperform Naive Bayes in classification tasks where feature sparsity is handled effectively.\n",
        "Expectation: SVM should have slightly higher accuracy and better balance in recall for negative reviews.\n",
        "\n",
        "Naive Bayes (TF-IDF)\n",
        "Expected to perform similarly to the CountVectorizer version, but TF-IDF might give a slight advantage in capturing key words rather than frequency-based importance.\n",
        "Works well when distinguishing sentiment using unique descriptive words.\n",
        "\n",
        "\n",
        "SVM (TF-IDF)\n",
        "Likely the best performer because SVM works well with TF-IDF representations where the focus is on weighted word importance rather than raw counts.\n",
        "Generally achieves higher accuracy and recall than Naive Bayes.\n",
        "\n",
        "observations on VADER Performance:\n",
        "Lexicon-based approaches struggle with context and sarcasm.\n",
        "The accuracy is expected to be lower than ML models, especially when dealing with complex review texts.\n",
        "VADER works better in short texts like tweets but not as well for detailed reviews.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "SVM + TF-IDF is expected to be the best performer in this dataset, as SVM works well with high-dimensional text data.\n",
        "Naive Bayes is fast and efficient but struggles with handling context.\n",
        "VADER (Lexicon-based) is the least effective as it does not learn from data, making it weaker in real-world sentiment prediction."
      ],
      "metadata": {
        "id": "EfiXJvCBLcR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acknowledgement :I referred to ChatGPT for initial guidance and structuring ideas in this assignment; however, the majority of the work, including analysis and implementation, was completed independently without collaboration or reliance on additional tools."
      ],
      "metadata": {
        "id": "gchnX6-cNZzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install jupyter nbconvert\n",
        "\n",
        "# Convert the Jupyter Notebook to an HTML file\n",
        "!jupyter nbconvert --to html \"/content/LA2_maurya_Bhima.ipynb\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMth_tP0atGZ",
        "outputId": "a724664c-085b-4310-dcf9-d1d488551bbf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (7.16.6)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.1.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.29.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (from jupyter) (4.3.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbconvert) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (2.18.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from nbclient>=0.5.0->nbconvert) (7.4.9)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert) (2.6)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter) (3.0.50)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (2.0.4)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (75.1.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.11.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.16.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.10.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat>=5.7->nbconvert) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.22)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20241206)\n",
            "[NbConvertApp] Converting notebook /content/LA2_maurya_Bhima.ipynb to html\n",
            "[NbConvertApp] Writing 307016 bytes to /content/LA2_maurya_Bhima.html\n"
          ]
        }
      ]
    }
  ]
}